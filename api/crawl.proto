syntax = "proto3";
package crawl;

// URLRequest defines the outgoing request.
// We can provide a URL and the state we want the client
// to put it in.
message URLRequest {
    enum command {
        // URLs in STOPPED, NONE, or DONE may be started.
        START = 0;
        // URLs in CRAWLING, STOPPED, or DONE may be stopped.
        STOP = 1;
        // URLs in any state may be checked.
        CHECK = 2;
    }
	string URL = 1;
    command state = 2;
}

// URLState reports the crawl status ONLY of a URL.
message URLState {
    enum Status {
        STOPPED = 0;  // Crawler has stopped crawling this URL.
                      // START for a STOPPED URL resumes the crawl.
                      // STOP for a STOPPED URL does nothing.
        RUNNING = 1;  // Crawler is actively crawling this URL.
                      // Once it completes the crawl, it switches
                      // the URL's state to DONE. START for a 
                      // CRAWLING URL is a no-op. STOP for a CRAWLING
                      // URL saves the URL's state and sets it to STOPPED.
        DONE = 2;     // Crawler has completed a crawl for this URL.
                      // If the crawler receives a START for a DONE
                      // URL, it discards the crawl history and 
                      // crawls it again. If it receives a STOP, it
                      // does nothing.
        UNKNOWN = 3;  // Crawler has never seen this URL before.
                      // This is a meta-state; URLs never crawled
                      // are not recorded in the client to avoid a
                      // possible DoS from a clog of never-crawled URLs.
                      // Only returned for a STOP.
        FAILED = 4;   // Crawl failed for some reason. 
    }
    Status status = 1;
    string Message = 2;

}

// SiteNode is returned in response to a STATUS request.
// It returns a tree of sitenodes found under the current
// URL (which may recursively contain more SiteNodes).
// If no URL is supplied, all the SiteNodes the crawler
// knows about are returned as the children of a SiteNode
// with the siteURL "all://".
message SiteNode {
    string siteURL = 1;
    string treeString = 2;
    string status = 3;
}

service Crawl {
    // Because we're calling the client from our CLI, we
    // want the CrawlSite API to make a single request
    // and wait for the response. This API lets us start,
    // stop, or check the status of a URL
    rpc CrawlSite (URLRequest) returns (URLState) {}
    // Checks the current status of a crawl and returns
    // the tree as it stands.
    rpc CrawlResult (URLRequest) returns (SiteNode) {}
}
