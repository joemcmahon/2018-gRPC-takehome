// Code generated by protoc-gen-go. DO NOT EDIT.
// source: crawl.proto

package crawl

import proto "github.com/golang/protobuf/proto"
import fmt "fmt"
import math "math"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.ProtoPackageIsVersion2 // please upgrade the proto package

type URLRequestCommand int32

const (
	// URLs in STOPPED, NONE, or DONE may be started.
	URLRequest_START URLRequestCommand = 0
	// URLS in CRAWLING, STOPPED, or DONE may be stopped.
	URLRequest_STOP URLRequestCommand = 1
)

var URLRequestCommand_name = map[int32]string{
	0: "START",
	1: "STOP",
}
var URLRequestCommand_value = map[string]int32{
	"START": 0,
	"STOP":  1,
}

func (x URLRequestCommand) String() string {
	return proto.EnumName(URLRequestCommand_name, int32(x))
}
func (URLRequestCommand) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_crawl_fc3fe5073539bfa3, []int{0, 0}
}

type URLStateUrlStatus int32

const (
	URLState_STOPPED URLStateUrlStatus = 0
	// START for a STOPPED URL resumes the crawl.
	// STOP for a STOPPED URL does nothing.
	URLState_CRAWLING URLStateUrlStatus = 1
	// Once it completes the crawl, it switches
	// the URL's state to DONE. START for a
	// CRAWLING URL is a no-op. STOP for a CRAWLING
	// URL saves the URL's state and sets it to STOPPED.
	URLState_DONE URLStateUrlStatus = 2
	// If the crawler receives a START for a DONE
	// URL, it discards the crawl history and
	// crawls it again. If it receives a STOP, it
	// does nothing.
	URLState_NEVER URLStateUrlStatus = 3
)

var URLStateUrlStatus_name = map[int32]string{
	0: "STOPPED",
	1: "CRAWLING",
	2: "DONE",
	3: "NEVER",
}
var URLStateUrlStatus_value = map[string]int32{
	"STOPPED":  0,
	"CRAWLING": 1,
	"DONE":     2,
	"NEVER":    3,
}

func (x URLStateUrlStatus) String() string {
	return proto.EnumName(URLStateUrlStatus_name, int32(x))
}
func (URLStateUrlStatus) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_crawl_fc3fe5073539bfa3, []int{1, 0}
}

// URLRequest defines the outgoing request.
// We can provide a URL and the state we want the client
// to put it in.
type URLRequest struct {
	URL                  string            `protobuf:"bytes,1,opt,name=URL,proto3" json:"URL,omitempty"`
	State                URLRequestCommand `protobuf:"varint,2,opt,name=state,proto3,enum=crawl.URLRequestCommand" json:"state,omitempty"`
	XXX_NoUnkeyedLiteral struct{}          `json:"-"`
	XXX_unrecognized     []byte            `json:"-"`
	XXX_sizecache        int32             `json:"-"`
}

func (m *URLRequest) Reset()         { *m = URLRequest{} }
func (m *URLRequest) String() string { return proto.CompactTextString(m) }
func (*URLRequest) ProtoMessage()    {}
func (*URLRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_crawl_fc3fe5073539bfa3, []int{0}
}
func (m *URLRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_URLRequest.Unmarshal(m, b)
}
func (m *URLRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_URLRequest.Marshal(b, m, deterministic)
}
func (dst *URLRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_URLRequest.Merge(dst, src)
}
func (m *URLRequest) XXX_Size() int {
	return xxx_messageInfo_URLRequest.Size(m)
}
func (m *URLRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_URLRequest.DiscardUnknown(m)
}

var xxx_messageInfo_URLRequest proto.InternalMessageInfo

func (m *URLRequest) GetURL() string {
	if m != nil {
		return m.URL
	}
	return ""
}

func (m *URLRequest) GetState() URLRequestCommand {
	if m != nil {
		return m.State
	}
	return URLRequest_START
}

// URLState reports the crawl status ONLY of a URL.
type URLState struct {
	Status               URLStateUrlStatus `protobuf:"varint,1,opt,name=status,proto3,enum=crawl.URLStateUrlStatus" json:"status,omitempty"`
	XXX_NoUnkeyedLiteral struct{}          `json:"-"`
	XXX_unrecognized     []byte            `json:"-"`
	XXX_sizecache        int32             `json:"-"`
}

func (m *URLState) Reset()         { *m = URLState{} }
func (m *URLState) String() string { return proto.CompactTextString(m) }
func (*URLState) ProtoMessage()    {}
func (*URLState) Descriptor() ([]byte, []int) {
	return fileDescriptor_crawl_fc3fe5073539bfa3, []int{1}
}
func (m *URLState) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_URLState.Unmarshal(m, b)
}
func (m *URLState) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_URLState.Marshal(b, m, deterministic)
}
func (dst *URLState) XXX_Merge(src proto.Message) {
	xxx_messageInfo_URLState.Merge(dst, src)
}
func (m *URLState) XXX_Size() int {
	return xxx_messageInfo_URLState.Size(m)
}
func (m *URLState) XXX_DiscardUnknown() {
	xxx_messageInfo_URLState.DiscardUnknown(m)
}

var xxx_messageInfo_URLState proto.InternalMessageInfo

func (m *URLState) GetStatus() URLStateUrlStatus {
	if m != nil {
		return m.Status
	}
	return URLState_STOPPED
}

// SiteNode is returned in response to a STATUS request.
// It returns a tree of sitenodes found under the current
// URL (which may recursively contain more SiteNodes).
// If no URL is supplied, all the SiteNodes the crawler
// knows about are returned as the children of a SiteNode
// with the siteURL "all://".
type SiteNode struct {
	SiteURL              string      `protobuf:"bytes,1,opt,name=siteURL,proto3" json:"siteURL,omitempty"`
	Children             []*SiteNode `protobuf:"bytes,2,rep,name=children,proto3" json:"children,omitempty"`
	XXX_NoUnkeyedLiteral struct{}    `json:"-"`
	XXX_unrecognized     []byte      `json:"-"`
	XXX_sizecache        int32       `json:"-"`
}

func (m *SiteNode) Reset()         { *m = SiteNode{} }
func (m *SiteNode) String() string { return proto.CompactTextString(m) }
func (*SiteNode) ProtoMessage()    {}
func (*SiteNode) Descriptor() ([]byte, []int) {
	return fileDescriptor_crawl_fc3fe5073539bfa3, []int{2}
}
func (m *SiteNode) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_SiteNode.Unmarshal(m, b)
}
func (m *SiteNode) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_SiteNode.Marshal(b, m, deterministic)
}
func (dst *SiteNode) XXX_Merge(src proto.Message) {
	xxx_messageInfo_SiteNode.Merge(dst, src)
}
func (m *SiteNode) XXX_Size() int {
	return xxx_messageInfo_SiteNode.Size(m)
}
func (m *SiteNode) XXX_DiscardUnknown() {
	xxx_messageInfo_SiteNode.DiscardUnknown(m)
}

var xxx_messageInfo_SiteNode proto.InternalMessageInfo

func (m *SiteNode) GetSiteURL() string {
	if m != nil {
		return m.SiteURL
	}
	return ""
}

func (m *SiteNode) GetChildren() []*SiteNode {
	if m != nil {
		return m.Children
	}
	return nil
}

func init() {
	proto.RegisterType((*URLRequest)(nil), "crawl.URLRequest")
	proto.RegisterType((*URLState)(nil), "crawl.URLState")
	proto.RegisterType((*SiteNode)(nil), "crawl.SiteNode")
	proto.RegisterEnum("crawl.URLRequestCommand", URLRequestCommand_name, URLRequestCommand_value)
	proto.RegisterEnum("crawl.URLStateUrlStatus", URLStateUrlStatus_name, URLStateUrlStatus_value)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// CrawlClient is the client API for Crawl service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type CrawlClient interface {
	// Because we're calling the client from our CLI, we
	// want the CrawlSite API to make a single request
	// and wait for the response.
	CrawlSite(ctx context.Context, in *URLRequest, opts ...grpc.CallOption) (*URLState, error)
	// I'm defining this this way so that if I'm mistaken and
	// I have to create a stream of SiteNode messages to
	// successfully return all the crawls, this will still work.
	URLStatus(ctx context.Context, in *URLRequest, opts ...grpc.CallOption) (Crawl_URLStatusClient, error)
}

type crawlClient struct {
	cc *grpc.ClientConn
}

func NewCrawlClient(cc *grpc.ClientConn) CrawlClient {
	return &crawlClient{cc}
}

func (c *crawlClient) CrawlSite(ctx context.Context, in *URLRequest, opts ...grpc.CallOption) (*URLState, error) {
	out := new(URLState)
	err := c.cc.Invoke(ctx, "/crawl.Crawl/CrawlSite", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *crawlClient) URLStatus(ctx context.Context, in *URLRequest, opts ...grpc.CallOption) (Crawl_URLStatusClient, error) {
	stream, err := c.cc.NewStream(ctx, &_Crawl_serviceDesc.Streams[0], "/crawl.Crawl/URLStatus", opts...)
	if err != nil {
		return nil, err
	}
	x := &crawlURLStatusClient{stream}
	if err := x.ClientStream.SendMsg(in); err != nil {
		return nil, err
	}
	if err := x.ClientStream.CloseSend(); err != nil {
		return nil, err
	}
	return x, nil
}

type Crawl_URLStatusClient interface {
	Recv() (*SiteNode, error)
	grpc.ClientStream
}

type crawlURLStatusClient struct {
	grpc.ClientStream
}

func (x *crawlURLStatusClient) Recv() (*SiteNode, error) {
	m := new(SiteNode)
	if err := x.ClientStream.RecvMsg(m); err != nil {
		return nil, err
	}
	return m, nil
}

// CrawlServer is the server API for Crawl service.
type CrawlServer interface {
	// Because we're calling the client from our CLI, we
	// want the CrawlSite API to make a single request
	// and wait for the response.
	CrawlSite(context.Context, *URLRequest) (*URLState, error)
	// I'm defining this this way so that if I'm mistaken and
	// I have to create a stream of SiteNode messages to
	// successfully return all the crawls, this will still work.
	URLStatus(*URLRequest, Crawl_URLStatusServer) error
}

func RegisterCrawlServer(s *grpc.Server, srv CrawlServer) {
	s.RegisterService(&_Crawl_serviceDesc, srv)
}

func _Crawl_CrawlSite_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(URLRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(CrawlServer).CrawlSite(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/crawl.Crawl/CrawlSite",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(CrawlServer).CrawlSite(ctx, req.(*URLRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Crawl_URLStatus_Handler(srv interface{}, stream grpc.ServerStream) error {
	m := new(URLRequest)
	if err := stream.RecvMsg(m); err != nil {
		return err
	}
	return srv.(CrawlServer).URLStatus(m, &crawlURLStatusServer{stream})
}

type Crawl_URLStatusServer interface {
	Send(*SiteNode) error
	grpc.ServerStream
}

type crawlURLStatusServer struct {
	grpc.ServerStream
}

func (x *crawlURLStatusServer) Send(m *SiteNode) error {
	return x.ServerStream.SendMsg(m)
}

var _Crawl_serviceDesc = grpc.ServiceDesc{
	ServiceName: "crawl.Crawl",
	HandlerType: (*CrawlServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CrawlSite",
			Handler:    _Crawl_CrawlSite_Handler,
		},
	},
	Streams: []grpc.StreamDesc{
		{
			StreamName:    "URLStatus",
			Handler:       _Crawl_URLStatus_Handler,
			ServerStreams: true,
		},
	},
	Metadata: "crawl.proto",
}

func init() { proto.RegisterFile("crawl.proto", fileDescriptor_crawl_fc3fe5073539bfa3) }

var fileDescriptor_crawl_fc3fe5073539bfa3 = []byte{
	// 301 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x7c, 0x91, 0xc1, 0x4b, 0xf3, 0x40,
	0x10, 0xc5, 0xb3, 0xed, 0x97, 0x36, 0x99, 0x7e, 0xd8, 0x75, 0x4e, 0xd1, 0x83, 0x94, 0x3d, 0x15,
	0x84, 0x68, 0xdb, 0xa3, 0xa7, 0xd2, 0x06, 0x11, 0x42, 0x5a, 0x37, 0xad, 0x9e, 0x63, 0xb2, 0x60,
	0x20, 0xed, 0x6a, 0xb2, 0x41, 0xf0, 0xaf, 0x97, 0xdd, 0x26, 0x2d, 0x2a, 0x78, 0x9b, 0x99, 0xfc,
	0xde, 0x7b, 0x33, 0x59, 0x18, 0xa4, 0x65, 0xf2, 0x51, 0xf8, 0x6f, 0xa5, 0x54, 0x12, 0x6d, 0xd3,
	0x30, 0x09, 0xb0, 0xe5, 0x21, 0x17, 0xef, 0xb5, 0xa8, 0x14, 0x52, 0xe8, 0x6e, 0x79, 0xe8, 0x91,
	0x11, 0x19, 0xbb, 0x5c, 0x97, 0x78, 0x03, 0x76, 0xa5, 0x12, 0x25, 0xbc, 0xce, 0x88, 0x8c, 0xcf,
	0xa6, 0x17, 0xfe, 0xc1, 0xe3, 0xa4, 0xf1, 0x53, 0xb9, 0xdb, 0x25, 0xfb, 0x8c, 0x1f, 0x38, 0x76,
	0x05, 0xfd, 0x66, 0x82, 0x2e, 0xd8, 0xf1, 0x66, 0xce, 0x37, 0xd4, 0x42, 0x07, 0xfe, 0xc5, 0x9b,
	0xd5, 0x9a, 0x12, 0xf6, 0x09, 0xce, 0x96, 0x87, 0xb1, 0x66, 0x71, 0x02, 0x3d, 0x2d, 0xaa, 0x2b,
	0x93, 0xf8, 0xcd, 0xdd, 0x00, 0x7e, 0x5d, 0x16, 0xb1, 0x01, 0x78, 0x03, 0xb2, 0x3b, 0x70, 0x8f,
	0x43, 0x1c, 0x40, 0x5f, 0xbb, 0xae, 0x83, 0x25, 0xb5, 0xf0, 0x3f, 0x38, 0x0b, 0x3e, 0x7f, 0x0e,
	0x1f, 0xa2, 0x7b, 0x4a, 0x74, 0xe0, 0x72, 0x15, 0x05, 0xb4, 0xa3, 0xb7, 0x88, 0x82, 0xa7, 0x80,
	0xd3, 0x2e, 0x7b, 0x04, 0x27, 0xce, 0x95, 0x88, 0x64, 0x26, 0xd0, 0x83, 0x7e, 0x95, 0x2b, 0x71,
	0x3a, 0xb7, 0x6d, 0xf1, 0x1a, 0x9c, 0xf4, 0x35, 0x2f, 0xb2, 0x52, 0xec, 0xbd, 0xce, 0xa8, 0x3b,
	0x1e, 0x4c, 0x87, 0xcd, 0x5e, 0xad, 0x98, 0x1f, 0x81, 0xa9, 0x04, 0x7b, 0xa1, 0xbf, 0xe1, 0x04,
	0x5c, 0x53, 0x68, 0x06, 0xcf, 0x7f, 0xfd, 0xa6, 0xcb, 0xe1, 0x8f, 0xdb, 0x98, 0x85, 0x33, 0x70,
	0x9b, 0xae, 0xae, 0xfe, 0x92, 0xb4, 0xb1, 0xcc, 0xba, 0x25, 0x2f, 0x3d, 0xf3, 0x7c, 0xb3, 0xaf,
	0x00, 0x00, 0x00, 0xff, 0xff, 0x10, 0x5a, 0xac, 0x80, 0xcd, 0x01, 0x00, 0x00,
}
